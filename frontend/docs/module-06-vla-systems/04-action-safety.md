# Chapter 4: Action Execution & Safety

## Introduction

In the previous chapter, you learned about cognitive planning with LLMs and how to convert high-level commands into detailed step-by-step execution plans with proper constraint enforcement. Now we'll explore how to safely execute these plans in the physical world through ROS 2 actions with monitoring and failure recovery.

Action execution in VLA systems requires careful attention to safety boundaries, as the plans generated by LLMs must be executed in the real world where physical constraints and uncertainties can lead to failures. This chapter covers mapping plans to ROS 2 actions, action monitoring and feedback, failure recovery strategies, and safety boundaries in embodied LLM systems.

This chapter emphasizes the critical importance of safety in VLA systems, where natural language commands can result in physical robot actions. You'll learn how to implement robust execution systems that can detect failures, re-plan when necessary, and ask for clarification when encountering unexpected situations.

By the end of this chapter, you'll understand how to safely execute VLA system plans in the physical world while maintaining the safety boundaries that protect both the robot and its environment.

## Core Concepts

### Mapping Plans to ROS 2 Actions

Mapping high-level plans to ROS 2 actions involves translating abstract plan steps into concrete ROS 2 action executions:

**Action Interface Mapping**: Converting plan step parameters into appropriate ROS 2 action goal messages with proper type definitions and validation.

**Execution Context**: Maintaining context information that allows ROS 2 action servers to execute actions with awareness of the overall plan and current state.

**Parameter Validation**: Validating action parameters before sending goals to ensure they meet ROS 2 message type requirements and safety constraints.

**Result Processing**: Converting ROS 2 action results back into plan execution context for monitoring and potential re-planning.

### Action Monitoring & Feedback

Action monitoring ensures that plan execution proceeds as expected and detects deviations or failures:

**Progress Tracking**: Monitoring action execution progress and comparing it against expected timelines and intermediate states.

**Success Criteria**: Defining clear success criteria for each action that can be objectively evaluated by monitoring systems.

**Anomaly Detection**: Identifying unexpected behaviors or deviations from expected execution patterns that may indicate problems.

**State Synchronization**: Keeping the planning system's understanding of the world synchronized with the actual state as actions are executed.

### Failure Recovery Strategies

Failure recovery strategies handle situations where actions do not execute as planned:

**Graceful Degradation**: Implementing fallback behaviors that maintain system safety when primary actions fail.

**Re-planning**: Detecting when the current plan cannot be executed and triggering the planning system to generate alternative approaches.

**Clarification Requests**: Asking for human input when the system encounters ambiguous or unclear situations during execution.

**Error Isolation**: Isolating the impact of individual action failures to prevent cascading failures in the overall plan.

### Safety Boundaries in Embodied LLMs

Safety boundaries ensure that LLM-generated plans are executed safely in the physical world:

**Physical Constraints**: Ensuring actions respect physical limits like joint angles, payload capacities, and workspace boundaries.

**Environmental Safety**: Implementing checks to prevent actions that could harm humans, objects, or the environment.

**Temporal Safety**: Managing execution timing to prevent dangerous situations like collisions or unstable robot configurations.

**Validation Gates**: Multiple safety checks before, during, and after action execution to ensure safe operation.

## Examples

### Example: Plan → ROS 2 Action Graph

Converting a validated plan into a ROS 2 action execution graph:

```yaml
# ROS 2 Action Graph Configuration
action_graph:
  name: "pick_up_bottle_from_table"
  nodes:
    - id: "approach_table"
      action_type: "move_base_msgs/MoveBaseAction"
      goal:
        target_pose:
          header:
            frame_id: "map"
          pose:
            position: {x: 1.0, y: 0.5, z: 0.0}
            orientation: {x: 0.0, y: 0.0, z: 0.0, w: 1.0}
      dependencies: []
      timeout: 30.0
      retry_policy:
        max_retries: 3
        backoff_factor: 1.5

    - id: "perceive_environment"
      action_type: "object_recognition_msgs/ObjectRecognitionAction"
      goal:
        object_type: "bottle"
        search_area:
          center: {x: 1.0, y: 0.5, z: 0.8}
          size: {x: 0.5, y: 0.5, z: 0.5}
      dependencies: ["approach_table"]
      timeout: 10.0

    - id: "plan_grasp"
      action_type: "grasp_planning_msgs/GraspPlanningAction"
      goal:
        object_id: "detected_bottle"
        grasp_type: "top_grasp"
      dependencies: ["perceive_environment"]
      timeout: 15.0

    - id: "execute_grasp"
      action_type: "manipulation_msgs/PickupAction"
      goal:
        grasp_plan: "computed_grasp"
        object_id: "detected_bottle"
      dependencies: ["plan_grasp"]
      timeout: 20.0
      safety_constraints:
        - max_force: 50.0  # Newtons
        - collision_check: true
        - force_feedback_monitoring: true

    - id: "lift_object"
      action_type: "control_msgs/FollowJointTrajectoryAction"
      goal:
        trajectory:
          joint_names: ["arm_joint_1", "arm_joint_2", "arm_joint_3"]
          points:
            - positions: [0.1, 0.2, 0.3]
              time_from_start: {sec: 2, nanosec: 0}
      dependencies: ["execute_grasp"]
      timeout: 10.0
      safety_constraints:
        - velocity_limits: true
        - acceleration_limits: true

  edges:
    - from: "approach_table"
      to: "perceive_environment"
    - from: "perceive_environment"
      to: "plan_grasp"
    - from: "plan_grasp"
      to: "execute_grasp"
    - from: "execute_grasp"
      to: "lift_object"

  safety_boundaries:
    - workspace_limits:
        min: {x: -1.0, y: -1.0, z: 0.0}
        max: {x: 2.0, y: 2.0, z: 2.0}
    - joint_limits:
        position: true
        velocity: true
        effort: true
    - collision_avoidance: true
    - human_safety_zone: 1.0  # meters

  monitoring_config:
    progress_check_interval: 1.0  # seconds
    anomaly_detection:
      enabled: true
      thresholds:
        execution_time_deviation: 2.0  # standard deviations
        position_error: 0.1  # meters
    feedback_frequency: 10.0  # Hz
```

This configuration shows how a high-level plan is converted into a graph of ROS 2 actions with dependencies, safety constraints, and monitoring configurations.

### Example: Detect Failure (Object Not Found) and Re-plan

Implementing failure detection and re-planning when an expected object is not found:

```python
# Example Python code for failure detection and re-planning
import rclpy
from rclpy.action import ActionClient
from rclpy.node import Node
from std_msgs.msg import String
from geometry_msgs.msg import Pose
from action_msgs.msg import GoalStatus
from object_recognition_msgs.action import ObjectRecognition
from manipulation_msgs.action import Pickup
from std_srvs.srv import Trigger
import asyncio
import json

class VLAExecutionManager(Node):
    def __init__(self):
        super().__init__('vla_execution_manager')

        # Action clients for different ROS 2 actions
        self.object_recognition_client = ActionClient(
            self, ObjectRecognition, 'recognize_objects')
        self.pickup_client = ActionClient(
            self, Pickup, 'pickup_object')

        # Service client for re-planning
        self.replan_client = self.create_client(
            Trigger, 'replan_action')

        # Publishers for monitoring and feedback
        self.status_publisher = self.create_publisher(
            String, 'vla_execution_status', 10)
        self.feedback_publisher = self.create_publisher(
            String, 'vla_execution_feedback', 10)

        # Current plan and execution state
        self.current_plan = None
        self.current_step_index = 0
        self.execution_state = 'idle'

        self.get_logger().info('VLA Execution Manager initialized')

    async def execute_plan(self, plan):
        """Execute a validated plan with monitoring and failure handling"""
        self.current_plan = plan
        self.current_step_index = 0
        self.execution_state = 'executing'

        self.publish_status('Starting plan execution')

        for step_index, step in enumerate(plan['plan']):
            self.current_step_index = step_index

            execution_result = await self.execute_single_step(step)

            if execution_result['status'] == 'success':
                self.publish_feedback(f'Step {step["step_id"]} completed successfully')
                continue
            elif execution_result['status'] == 'failure':
                self.publish_status(f'Step {step["step_id"]} failed: {execution_result["error"]}')

                # Handle specific failure types
                if execution_result['failure_type'] == 'object_not_found':
                    re_plan_result = await self.handle_object_not_found(step, plan)
                    if re_plan_result['status'] == 'success':
                        # Retry execution with new plan
                        return await self.execute_plan(re_plan_result['new_plan'])
                    else:
                        self.publish_status('Re-planning failed, aborting execution')
                        return {'status': 'aborted', 'reason': 'replanning_failed'}

                elif execution_result['failure_type'] == 'grasp_failure':
                    recovery_result = await self.handle_grasp_failure(step)
                    if recovery_result['status'] == 'recovered':
                        continue  # Continue with next step
                    else:
                        return {'status': 'failed', 'reason': 'grasp_failure_unrecoverable'}

                else:
                    self.publish_status(f'Unhandled failure: {execution_result["error"]}')
                    return {'status': 'failed', 'reason': execution_result['error']}

        self.execution_state = 'completed'
        self.publish_status('Plan execution completed successfully')
        return {'status': 'success'}

    async def execute_single_step(self, step):
        """Execute a single plan step and return result"""
        try:
            if step['action'] == 'perceive_environment':
                return await self.execute_perception_step(step)
            elif step['action'] == 'execute_grasp':
                return await self.execute_grasp_step(step)
            elif step['action'] == 'approach_location':
                return await self.execute_approach_step(step)
            else:
                return {
                    'status': 'failure',
                    'error': f'Unknown action type: {step["action"]}',
                    'failure_type': 'unknown_action'
                }
        except Exception as e:
            return {
                'status': 'failure',
                'error': str(e),
                'failure_type': 'execution_error'
            }

    async def execute_perception_step(self, step):
        """Execute perception step and check for expected objects"""
        self.get_logger().info(f'Executing perception step: {step["step_id"]}')

        # Wait for action server
        self.object_recognition_client.wait_for_server()

        # Create goal
        goal_msg = ObjectRecognition.Goal()
        goal_msg.object_type = step['parameters']['target_object']
        goal_msg.search_area = self.create_search_area(
            step['parameters']['search_area'])

        # Send goal
        goal_future = self.object_recognition_client.send_goal_async(goal_msg)
        goal_handle = await goal_future

        if not goal_handle.accepted:
            return {
                'status': 'failure',
                'error': 'Goal rejected by server',
                'failure_type': 'server_rejection'
            }

        # Get result
        result_future = goal_handle.get_result_async()
        result = await result_future

        # Check if object was found
        if result.result.found_objects and len(result.result.found_objects) > 0:
            self.get_logger().info('Object found successfully')
            return {'status': 'success'}
        else:
            self.get_logger().warn('Object not found in expected location')
            return {
                'status': 'failure',
                'error': 'Target object not found',
                'failure_type': 'object_not_found'
            }

    async def execute_grasp_step(self, step):
        """Execute grasp step with force feedback monitoring"""
        self.get_logger().info(f'Executing grasp step: {step["step_id"]}')

        self.pickup_client.wait_for_server()

        goal_msg = Pickup.Goal()
        goal_msg.object_id = step['parameters']['object_id']
        goal_msg.grasp_pose = self.create_grasp_pose(
            step['parameters']['grasp_pose'])

        goal_future = self.pickup_client.send_goal_async(goal_msg)
        goal_handle = await goal_future

        if not goal_handle.accepted:
            return {
                'status': 'failure',
                'error': 'Grasp goal rejected',
                'failure_type': 'grasp_rejection'
            }

        result_future = goal_handle.get_result_async()
        result = await result_future

        if result.result.success:
            self.get_logger().info('Grasp completed successfully')
            return {'status': 'success'}
        else:
            self.get_logger().warn(f'Grasp failed: {result.result.error_message}')
            return {
                'status': 'failure',
                'error': result.result.error_message,
                'failure_type': 'grasp_failure'
            }

    async def handle_object_not_found(self, failed_step, original_plan):
        """Handle the case where expected object is not found"""
        self.get_logger().info('Handling object not found scenario')

        # Request clarification from user
        clarification_needed = {
            'type': 'object_not_found',
            'step_id': failed_step['step_id'],
            'expected_object': failed_step['parameters']['target_object'],
            'search_area': failed_step['parameters']['search_area']
        }

        self.publish_status('Object not found, requesting clarification or re-planning')

        # Option 1: Ask for clarification
        user_response = await self.request_user_clarification(clarification_needed)

        if user_response['action'] == 'reposition_search':
            # Modify the plan to search in a different location
            new_plan = await self.modify_plan_for_new_location(
                original_plan, failed_step, user_response['new_location'])
            return {'status': 'success', 'new_plan': new_plan}

        elif user_response['action'] == 'different_object':
            # Modify the plan to look for a different object
            new_plan = await self.modify_plan_for_different_object(
                original_plan, failed_step, user_response['new_object'])
            return {'status': 'success', 'new_plan': new_plan}

        elif user_response['action'] == 'abort':
            return {'status': 'failure', 'reason': 'user_aborted'}

        # Option 2: Try re-planning if no user input
        else:
            return await self.request_replanning(original_plan, failed_step)

    async def handle_grasp_failure(self, failed_step):
        """Handle grasp failure with recovery strategies"""
        self.get_logger().info('Handling grasp failure')

        # Try alternative grasp approach
        alternative_grasps = [
            'side_grasp',
            'bottom_grasp',
            'suction_grasp'
        ]

        for grasp_type in alternative_grasps:
            self.get_logger().info(f'Trying alternative grasp: {grasp_type}')

            try:
                # Attempt alternative grasp
                success = await self.attempt_alternative_grasp(
                    failed_step, grasp_type)

                if success:
                    self.get_logger().info(f'Alternative grasp {grasp_type} successful')
                    return {'status': 'recovered'}

            except Exception as e:
                self.get_logger().warn(f'Alternative grasp {grasp_type} failed: {str(e)}')
                continue

        return {'status': 'failed', 'reason': 'all_grasp_attempts_failed'}

    async def request_user_clarification(self, issue_details):
        """Request clarification from user when encountering issues"""
        # In a real system, this would interface with a user interaction system
        # For this example, we'll simulate user response

        self.get_logger().info(f'Requesting clarification: {issue_details}')

        # Simulate user response - in real system this would wait for actual user input
        # For demonstration, return a default response
        return {
            'action': 'reposition_search',
            'new_location': {'x': 1.2, 'y': 0.6, 'z': 0.8}
        }

    async def request_replanning(self, original_plan, failed_step):
        """Request re-planning from the planning system"""
        self.get_logger().info('Requesting re-planning due to execution failure')

        if not self.replan_client.service_is_ready():
            return {'status': 'failure', 'reason': 'replan_service_not_available'}

        request = Trigger.Request()
        future = self.replan_client.call_async(request)

        try:
            response = await future
            if response.success:
                # In a real system, the replan service would return a new plan
                # For this example, we'll return a placeholder
                return {
                    'status': 'success',
                    'new_plan': original_plan  # Placeholder - would be new plan in real system
                }
            else:
                return {'status': 'failure', 'reason': 'replan_service_failed'}
        except Exception as e:
            return {'status': 'failure', 'reason': f'replan_request_failed: {str(e)}'}

    def publish_status(self, status_msg):
        """Publish execution status"""
        status = String()
        status.data = status_msg
        self.status_publisher.publish(status)

    def publish_feedback(self, feedback_msg):
        """Publish execution feedback"""
        feedback = String()
        feedback.data = feedback_msg
        self.feedback_publisher.publish(feedback)

def main(args=None):
    rclpy.init(args=args)
    executor = rclpy.executors.MultiThreadedExecutor()

    execution_manager = VLAExecutionManager()
    executor.add_node(execution_manager)

    try:
        executor.spin()
    except KeyboardInterrupt:
        pass
    finally:
        execution_manager.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
```

### Example: Safety Boundary Implementation

Implementing comprehensive safety boundaries for VLA system execution:

```python
# Complete safety boundary implementation
import threading
import time
from enum import Enum
from dataclasses import dataclass
from typing import Dict, List, Any, Optional
import math

class SafetyLevel(Enum):
    CRITICAL = "critical"
    WARNING = "warning"
    INFO = "info"

@dataclass
class SafetyConstraint:
    name: str
    constraint_type: str
    parameters: Dict[str, Any]
    enabled: bool = True

class SafetyBoundaryManager:
    def __init__(self):
        self.constraints = []
        self.active_monitoring = True
        self.safety_violations = []
        self.emergency_stop_active = False
        self.monitoring_thread = None

        # Initialize default safety constraints
        self._initialize_default_constraints()

    def _initialize_default_constraints(self):
        """Initialize default safety constraints for VLA systems"""
        self.constraints = [
            SafetyConstraint(
                name="workspace_boundary",
                constraint_type="position",
                parameters={
                    "min_position": {"x": -2.0, "y": -2.0, "z": 0.0},
                    "max_position": {"x": 2.0, "y": 2.0, "z": 2.0}
                }
            ),
            SafetyConstraint(
                name="joint_limits",
                constraint_type="joint",
                parameters={
                    "max_velocity": 1.0,  # rad/s
                    "max_effort": 100.0,  # Nm
                    "position_bounds": {
                        "min": [-3.14, -1.57, -3.14],
                        "max": [3.14, 1.57, 3.14]
                    }
                }
            ),
            SafetyConstraint(
                name="human_safety_zone",
                constraint_type="proximity",
                parameters={
                    "safe_distance": 1.0,  # meters
                    "detection_threshold": 0.8  # confidence for human detection
                }
            ),
            SafetyConstraint(
                name="payload_limit",
                constraint_type="force",
                parameters={
                    "max_payload": 5.0,  # kg
                    "max_force": 100.0   # Newtons
                }
            ),
            SafetyConstraint(
                name="collision_avoidance",
                constraint_type="collision",
                parameters={
                    "min_distance": 0.1,  # meters
                    "buffer_zone": 0.05   # meters
                }
            )
        ]

    def start_monitoring(self):
        """Start continuous safety monitoring"""
        if self.monitoring_thread is None:
            self.active_monitoring = True
            self.monitoring_thread = threading.Thread(target=self._monitoring_loop)
            self.monitoring_thread.daemon = True
            self.monitoring_thread.start()
            print("Safety monitoring started")

    def stop_monitoring(self):
        """Stop safety monitoring"""
        self.active_monitoring = False
        if self.monitoring_thread:
            self.monitoring_thread.join()
        print("Safety monitoring stopped")

    def _monitoring_loop(self):
        """Continuous monitoring loop"""
        while self.active_monitoring:
            if not self.emergency_stop_active:
                self._check_all_constraints()
            time.sleep(0.1)  # Check every 100ms

    def _check_all_constraints(self):
        """Check all active safety constraints"""
        current_state = self._get_current_robot_state()

        for constraint in self.constraints:
            if constraint.enabled:
                result = self._evaluate_constraint(constraint, current_state)
                if result['violation']:
                    self._handle_violation(constraint, result)

    def _evaluate_constraint(self, constraint: SafetyConstraint, state: Dict[str, Any]) -> Dict[str, Any]:
        """Evaluate a specific safety constraint"""
        if constraint.constraint_type == "position":
            return self._check_position_constraint(constraint, state)
        elif constraint.constraint_type == "joint":
            return self._check_joint_constraint(constraint, state)
        elif constraint.constraint_type == "proximity":
            return self._check_proximity_constraint(constraint, state)
        elif constraint.constraint_type == "force":
            return self._check_force_constraint(constraint, state)
        elif constraint.constraint_type == "collision":
            return self._check_collision_constraint(constraint, state)
        else:
            return {"violation": False, "message": "Unknown constraint type"}

    def _check_position_constraint(self, constraint: SafetyConstraint, state: Dict[str, Any]) -> Dict[str, Any]:
        """Check position boundary constraints"""
        current_pos = state.get('position', {'x': 0, 'y': 0, 'z': 0})
        min_pos = constraint.parameters['min_position']
        max_pos = constraint.parameters['max_position']

        violation = (
            current_pos['x'] < min_pos['x'] or current_pos['x'] > max_pos['x'] or
            current_pos['y'] < min_pos['y'] or current_pos['y'] > max_pos['y'] or
            current_pos['z'] < min_pos['z'] or current_pos['z'] > max_pos['z']
        )

        if violation:
            return {
                "violation": True,
                "level": SafetyLevel.CRITICAL,
                "message": f"Position boundary violation: {current_pos} outside [{min_pos}, {max_pos}]",
                "current_value": current_pos,
                "bounds": [min_pos, max_pos]
            }

        return {"violation": False}

    def _check_joint_constraint(self, constraint: SafetyConstraint, state: Dict[str, Any]) -> Dict[str, Any]:
        """Check joint limit constraints"""
        current_joints = state.get('joints', [])
        position_bounds = constraint.parameters['position_bounds']

        # Check position limits
        for i, pos in enumerate(current_joints.get('positions', [])):
            if i < len(position_bounds['min']) and i < len(position_bounds['max']):
                if pos < position_bounds['min'][i] or pos > position_bounds['max'][i]:
                    return {
                        "violation": True,
                        "level": SafetyLevel.CRITICAL,
                        "message": f"Joint position limit violation: joint {i} at {pos}",
                        "current_value": pos,
                        "bounds": [position_bounds['min'][i], position_bounds['max'][i]]
                    }

        # Check velocity limits
        max_velocity = constraint.parameters['max_velocity']
        current_velocities = current_joints.get('velocities', [])
        for vel in current_velocities:
            if abs(vel) > max_velocity:
                return {
                    "violation": True,
                    "level": SafetyLevel.WARNING,
                    "message": f"Joint velocity limit violation: {vel} > {max_velocity}",
                    "current_value": vel,
                    "limit": max_velocity
                }

        return {"violation": False}

    def _check_proximity_constraint(self, constraint: SafetyConstraint, state: Dict[str, Any]) -> Dict[str, Any]:
        """Check proximity to humans or obstacles"""
        safe_distance = constraint.parameters['safe_distance']
        human_detections = state.get('human_detections', [])

        for detection in human_detections:
            distance = detection.get('distance', float('inf'))
            if distance < safe_distance:
                return {
                    "violation": True,
                    "level": SafetyLevel.WARNING,
                    "message": f"Human proximity violation: {distance:.2f}m < {safe_distance}m",
                    "current_value": distance,
                    "limit": safe_distance,
                    "human_position": detection.get('position')
                }

        return {"violation": False}

    def _check_force_constraint(self, constraint: SafetyConstraint, state: Dict[str, Any]) -> Dict[str, Any]:
        """Check force and payload constraints"""
        current_payload = state.get('current_payload', 0.0)
        max_payload = constraint.parameters['max_payload']

        if current_payload > max_payload:
            return {
                "violation": True,
                "level": SafetyLevel.CRITICAL,
                "message": f"Payload limit violation: {current_payload}kg > {max_payload}kg",
                "current_value": current_payload,
                "limit": max_payload
            }

        return {"violation": False}

    def _check_collision_constraint(self, constraint: SafetyConstraint, state: Dict[str, Any]) -> Dict[str, Any]:
        """Check for potential collisions"""
        min_distance = constraint.parameters['min_distance']
        obstacles = state.get('obstacles', [])

        for obstacle in obstacles:
            distance = obstacle.get('distance', float('inf'))
            if distance < min_distance:
                return {
                    "violation": True,
                    "level": SafetyLevel.CRITICAL,
                    "message": f"Collision risk: obstacle at {distance:.2f}m < {min_distance}m",
                    "current_value": distance,
                    "limit": min_distance,
                    "obstacle_position": obstacle.get('position')
                }

        return {"violation": False}

    def _handle_violation(self, constraint: SafetyConstraint, violation_result: Dict[str, Any]):
        """Handle a safety constraint violation"""
        self.safety_violations.append({
            'timestamp': time.time(),
            'constraint': constraint.name,
            'result': violation_result
        })

        if violation_result['level'] == SafetyLevel.CRITICAL:
            self.trigger_emergency_stop()

        print(f"Safety violation: {violation_result['message']}")

        # Log the violation for analysis
        self._log_violation(constraint, violation_result)

    def trigger_emergency_stop(self):
        """Trigger emergency stop for critical violations"""
        if not self.emergency_stop_active:
            print("EMERGENCY STOP TRIGGERED - Critical safety violation detected")
            self.emergency_stop_active = True
            # In a real system, this would send emergency stop commands to all controllers

    def clear_emergency_stop(self):
        """Clear emergency stop condition"""
        self.emergency_stop_active = False
        print("Emergency stop cleared")

    def _get_current_robot_state(self) -> Dict[str, Any]:
        """Get current robot state for monitoring (simulated)"""
        # In a real system, this would interface with the robot's state estimation
        return {
            'position': {'x': 0.5, 'y': 0.3, 'z': 0.8},
            'joints': {
                'positions': [0.1, 0.2, 0.3],
                'velocities': [0.05, 0.03, 0.02]
            },
            'current_payload': 2.5,
            'human_detections': [],
            'obstacles': []
        }

    def _log_violation(self, constraint: SafetyConstraint, violation_result: Dict[str, Any]):
        """Log safety violation for analysis"""
        # In a real system, this would write to a safety log file
        pass

    def validate_action_safety(self, action: Dict[str, Any]) -> Dict[str, Any]:
        """Validate a specific action against safety constraints before execution"""
        validation_result = {
            'safe': True,
            'violations': [],
            'warnings': []
        }

        # Check if emergency stop is active
        if self.emergency_stop_active:
            validation_result['safe'] = False
            validation_result['violations'].append("Emergency stop is active")
            return validation_result

        # Validate action parameters against constraints
        for constraint in self.constraints:
            if constraint.enabled and constraint.name != "collision_avoidance":
                # For this example, we'll do basic validation
                # In a real system, this would be more detailed
                pass

        return validation_result

# Example usage in VLA execution system
class SafeVLAExecutionSystem:
    def __init__(self):
        self.safety_manager = SafetyBoundaryManager()
        self.safety_manager.start_monitoring()

    async def execute_action_safely(self, action: Dict[str, Any]):
        """Execute an action with safety validation"""
        # Validate action before execution
        validation = self.safety_manager.validate_action_safety(action)

        if not validation['safe']:
            return {
                'status': 'blocked',
                'reason': 'Safety validation failed',
                'violations': validation['violations']
            }

        # Execute the action (in a real system, this would interface with ROS 2)
        try:
            # Simulate action execution
            execution_result = await self._execute_ros2_action(action)

            return {
                'status': 'completed',
                'result': execution_result
            }
        except Exception as e:
            return {
                'status': 'failed',
                'error': str(e)
            }

    async def _execute_ros2_action(self, action: Dict[str, Any]):
        """Execute ROS 2 action (simulated)"""
        # Simulate action execution
        await asyncio.sleep(0.1)  # Simulate execution time
        return {'success': True, 'details': 'Action completed successfully'}

    def shutdown(self):
        """Shutdown the safety system"""
        self.safety_manager.stop_monitoring()
```

## Summary & Key Takeaways

In this chapter, you've learned about action execution and safety in VLA systems:

- **Mapping plans to ROS 2 actions** involves converting high-level plan steps into concrete action executions with proper parameters and dependencies
- **Action monitoring and feedback** ensures that plan execution proceeds as expected and detects deviations or failures
- **Failure recovery strategies** handle situations where actions fail, including re-planning and clarification requests
- **Safety boundaries** provide multiple layers of protection to ensure safe operation in the physical world

You've seen practical examples of converting plans to ROS 2 action graphs, implementing failure detection and re-planning when objects aren't found, and creating comprehensive safety boundary systems. The emphasis throughout is on maintaining safety while enabling effective robot operation in response to natural language commands.

These execution and safety systems complete the VLA architecture, providing the critical safety layer that enables LLM-generated plans to be safely executed in the physical world. The separation of planning from execution, combined with comprehensive safety monitoring and failure recovery, enables the development of robust and safe VLA systems that can bridge human intent with physical robot actions.

This concludes Module 6: Vision–Language–Action (VLA) Systems. You now have a comprehensive understanding of how to design, plan, and safely execute VLA systems that can interpret natural language commands and execute them through physical robot actions while maintaining the safety and determinism required for real-world deployment. These foundations prepare you for the capstone autonomous humanoid system.