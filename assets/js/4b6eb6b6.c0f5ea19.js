"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[274],{614(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"module-07-humanoid-hri/manipulation-grasping","title":"Chapter 3: Manipulation & Grasping","description":"Introduction","source":"@site/docs/module-07-humanoid-hri/manipulation-grasping.md","sourceDirName":"module-07-humanoid-hri","slug":"/module-07-humanoid-hri/manipulation-grasping","permalink":"/docs/module-07-humanoid-hri/manipulation-grasping","draft":false,"unlisted":false,"editUrl":"https://github.com/muhammadNadeem92/physical-ai-humanoid-robotics-textbook/tree/main/docs/module-07-humanoid-hri/manipulation-grasping.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 2: Bipedal Locomotion & Balance","permalink":"/docs/module-07-humanoid-hri/bipedal-locomotion"},"next":{"title":"Chapter 4: Human\u2013Robot Interaction (HRI)","permalink":"/docs/module-07-humanoid-hri/human-robot-interaction"}}');var s=i(4848),a=i(8453);const t={},o="Chapter 3: Manipulation & Grasping",l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Core Concepts",id:"core-concepts",level:2},{value:"End-Effectors",id:"end-effectors",level:3},{value:"Grasp Types",id:"grasp-types",level:3},{value:"Visual Servoing",id:"visual-servoing",level:3},{value:"Reachability Constraints",id:"reachability-constraints",level:3},{value:"Examples",id:"examples",level:2},{value:"Example: Object Pickup Pipeline",id:"example-object-pickup-pipeline",level:3},{value:"Example: Grasp Selection Logic (Diagrammatic)",id:"example-grasp-selection-logic-diagrammatic",level:3},{value:"Example: Manipulation State Transitions",id:"example-manipulation-state-transitions",level:3},{value:"Summary &amp; Key Takeaways",id:"summary--key-takeaways",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"chapter-3-manipulation--grasping",children:"Chapter 3: Manipulation & Grasping"})}),"\n",(0,s.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(e.p,{children:"This chapter teaches object interaction with humanoid hands. You'll learn about different grasp types, end-effectors, visual servoing, and reachability constraints that affect manipulation planning."}),"\n",(0,s.jsx)(e.p,{children:"Manipulation is a critical capability for humanoid robots to interact with their environment, building on the mechanical understanding from Chapter 1 but adding interaction-specific concepts. Understanding how robots can manipulate objects safely and effectively is essential for practical humanoid applications."}),"\n",(0,s.jsx)(e.p,{children:"By the end of this chapter, you'll understand how robots can manipulate objects safely and how to select appropriate grasps based on object properties and task requirements, preparing you for human-robot interaction concepts in the final chapter."}),"\n",(0,s.jsx)(e.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,s.jsx)(e.h3,{id:"end-effectors",children:"End-Effectors"}),"\n",(0,s.jsx)(e.p,{children:"End-effectors are the tools or devices at the end of a robot arm designed to interact with the environment."}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Types of End-Effectors:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Grippers"}),": Two or more fingers that can grasp objects","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Parallel jaw grippers: Simple and robust"}),"\n",(0,s.jsx)(e.li,{children:"Adaptive grippers: Can grasp objects of various shapes"}),"\n",(0,s.jsx)(e.li,{children:"Underactuated grippers: Use compliance for stable grasps"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Specialized Tools"}),": Designed for specific tasks","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Suction cups: For flat, smooth objects"}),"\n",(0,s.jsx)(e.li,{children:"Magnetic grippers: For ferromagnetic objects"}),"\n",(0,s.jsx)(e.li,{children:"Custom tools: For specific applications"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Key Characteristics:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Degrees of freedom and range of motion"}),"\n",(0,s.jsx)(e.li,{children:"Force and torque capabilities"}),"\n",(0,s.jsx)(e.li,{children:"Precision and accuracy"}),"\n",(0,s.jsx)(e.li,{children:"Adaptability to object shapes"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"grasp-types",children:"Grasp Types"}),"\n",(0,s.jsx)(e.p,{children:"Classification of how a robot hand grips an object, each serving different purposes."}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Power Grasp:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Focuses on stability and force application"}),"\n",(0,s.jsx)(e.li,{children:"Fingers wrap around object for maximum contact"}),"\n",(0,s.jsx)(e.li,{children:"Used for heavy lifting or forceful manipulation"}),"\n",(0,s.jsx)(e.li,{children:"Examples: Cylindrical grasp, spherical grasp, hook grasp"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Precision Grasp:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Focuses on fine control and dexterity"}),"\n",(0,s.jsx)(e.li,{children:"Uses fingertips for precise positioning"}),"\n",(0,s.jsx)(e.li,{children:"Used for delicate objects or precise placement"}),"\n",(0,s.jsx)(e.li,{children:"Examples: Pinch grasp, lateral grasp, tip grasp"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Grasp Stability Factors:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Contact points and friction"}),"\n",(0,s.jsx)(e.li,{children:"Object geometry and weight"}),"\n",(0,s.jsx)(e.li,{children:"Applied forces and torques"}),"\n",(0,s.jsx)(e.li,{children:"Environmental constraints"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"visual-servoing",children:"Visual Servoing"}),"\n",(0,s.jsx)(e.p,{children:"Using visual feedback to control robot motion and improve manipulation accuracy."}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Types of Visual Servoing:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Image-based"}),": Uses image features directly for control"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Position-based"}),": Uses 3D object pose for control"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Hybrid approaches"}),": Combines both methods"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Key Components:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Camera systems for visual feedback"}),"\n",(0,s.jsx)(e.li,{children:"Image processing algorithms"}),"\n",(0,s.jsx)(e.li,{children:"Control algorithms for motion adjustment"}),"\n",(0,s.jsx)(e.li,{children:"Integration with robot kinematics"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"reachability-constraints",children:"Reachability Constraints"}),"\n",(0,s.jsx)(e.p,{children:"Limits on where robots can reach based on their kinematic structure and environmental obstacles."}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Kinematic Constraints:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Joint limits and range of motion"}),"\n",(0,s.jsx)(e.li,{children:"Workspace boundaries of the robot"}),"\n",(0,s.jsx)(e.li,{children:"Singularity avoidance"}),"\n",(0,s.jsx)(e.li,{children:"Collision avoidance with robot body"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Environmental Constraints:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Obstacles in the workspace"}),"\n",(0,s.jsx)(e.li,{children:"Surface constraints (e.g., objects on tables)"}),"\n",(0,s.jsx)(e.li,{children:"Safety zones around humans"}),"\n",(0,s.jsx)(e.li,{children:"Task-specific constraints"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"examples",children:"Examples"}),"\n",(0,s.jsx)(e.h3,{id:"example-object-pickup-pipeline",children:"Example: Object Pickup Pipeline"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"1. Object Detection:\r\n   - Identify target object in environment\r\n   - Determine object pose and properties\r\n   - Assess accessibility and graspability\r\n\r\n2. Grasp Planning:\r\n   - Select appropriate grasp type based on object properties\r\n   - Calculate grasp pose and approach direction\r\n   - Verify grasp stability and reachability\r\n\r\n3. Approach Execution:\r\n   - Plan collision-free trajectory to approach pose\r\n   - Execute approach motion with safety monitoring\r\n   - Adjust approach based on visual feedback\r\n\r\n4. Grasp Execution:\r\n   - Execute grasp motion with appropriate force control\r\n   - Verify successful grasp through sensor feedback\r\n   - Lift object with stable grasp maintained\r\n\r\n5. Transport:\r\n   - Plan safe transport trajectory\r\n   - Execute transport with object stability maintained\r\n   - Prepare for placement at destination\n"})}),"\n",(0,s.jsx)(e.h3,{id:"example-grasp-selection-logic-diagrammatic",children:"Example: Grasp Selection Logic (Diagrammatic)"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Object Properties \u2192 Grasp Selection \u2192 Grasp Parameters\r\n     \u2193                   \u2193                  \u2193\r\nShape & Size    \u2192   Power vs Precision  \u2192  Contact Points\r\nWeight & CG     \u2192   Force Requirements  \u2192  Grasp Pose\r\nSurface Props   \u2192   Stability Analysis  \u2192  Approach Dir\r\nTask Context    \u2192   Environmental      \u2192  Force Control\r\n                 \u2192   Constraints        \u2192  Safety Margins\n"})}),"\n",(0,s.jsx)(e.h3,{id:"example-manipulation-state-transitions",children:"Example: Manipulation State Transitions"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Idle \u2192 Reachable \u2192 Grasping \u2192 Manipulating \u2192 Releasing \u2192 Idle\r\n  \u2191        \u2193          \u2193           \u2193            \u2193           \u2193\r\nHome   Approach   Grasp     Task Exec    Place      Home\r\nState    Motion    Success   Motion      Success   State\n"})}),"\n",(0,s.jsx)(e.h2,{id:"summary--key-takeaways",children:"Summary & Key Takeaways"}),"\n",(0,s.jsx)(e.p,{children:"In this chapter, you learned about manipulation and grasping:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"End-effectors"})," come in various types (grippers, tools) with different capabilities and characteristics"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Grasp types"})," include power grasps (stability) and precision grasps (dexterity) for different tasks"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Visual servoing"})," uses visual feedback to improve manipulation accuracy"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Reachability constraints"})," limit where robots can interact with objects"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"These concepts explain how humanoid robots can interact with objects in their environment, building on the kinematic and locomotion foundations from previous chapters and preparing for human-robot interaction in the final chapter."})]})}function p(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453(n,e,i){i.d(e,{R:()=>t,x:()=>o});var r=i(6540);const s={},a=r.createContext(s);function t(n){const e=r.useContext(a);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:t(n.components),r.createElement(a.Provider,{value:e},n.children)}}}]);