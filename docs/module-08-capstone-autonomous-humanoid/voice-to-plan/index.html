<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-08-capstone-autonomous-humanoid/voice-to-plan" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Chapter 2: Voice-to-Plan Pipeline | Physical AI &amp; Humanoid Robotics Textbook</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://muhammadNadeem92.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://muhammadNadeem92.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://muhammadNadeem92.github.io/docs/module-08-capstone-autonomous-humanoid/voice-to-plan"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Chapter 2: Voice-to-Plan Pipeline | Physical AI &amp; Humanoid Robotics Textbook"><meta data-rh="true" name="description" content="Introduction"><meta data-rh="true" property="og:description" content="Introduction"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://muhammadNadeem92.github.io/docs/module-08-capstone-autonomous-humanoid/voice-to-plan"><link data-rh="true" rel="alternate" href="https://muhammadNadeem92.github.io/docs/module-08-capstone-autonomous-humanoid/voice-to-plan" hreflang="en"><link data-rh="true" rel="alternate" href="https://muhammadNadeem92.github.io/docs/module-08-capstone-autonomous-humanoid/voice-to-plan" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Chapter 2: Voice-to-Plan Pipeline","item":"https://muhammadNadeem92.github.io/docs/module-08-capstone-autonomous-humanoid/voice-to-plan"}]}</script><link rel="stylesheet" href="/assets/css/styles.a5af11bd.css">
<script src="/assets/js/runtime~main.19f5b8f6.js" defer="defer"></script>
<script src="/assets/js/main.88e53483.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/frontend/static/img/book logo.jpg" alt="Physical AI &amp; Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/frontend/static/img/book logo.jpg" alt="Physical AI &amp; Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Textbook</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/muhammadNadeem92/physical-ai-humanoid-robotics-textbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro"><span title="Introduction to Physical AI &amp; Humanoid Robotics" class="linkLabel_WmDU">Introduction to Physical AI &amp; Humanoid Robotics</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-01-introduction/what-is-physical-ai"><span title="Module 1: Introduction to Physical AI &amp; Humanoid Robotics" class="categoryLinkLabel_W154">Module 1: Introduction to Physical AI &amp; Humanoid Robotics</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-02-ros2/architecture-setup"><span title="Module 2: ROS 2 — The Robotic Nervous System" class="categoryLinkLabel_W154">Module 2: ROS 2 — The Robotic Nervous System</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-03-sim-fundamentals/robot-description-models"><span title="Module 3: Robot Modeling &amp; Simulation Fundamentals" class="categoryLinkLabel_W154">Module 3: Robot Modeling &amp; Simulation Fundamentals</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-04-digital-twin/digital-twin-concepts"><span title="Module 4: The Digital Twin: Gazebo &amp; Unity Simulation" class="categoryLinkLabel_W154">Module 4: The Digital Twin: Gazebo &amp; Unity Simulation</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-05-isaac-ai-brain/isaac-architecture"><span title="Module 5: The AI Robot Brain: NVIDIA Isaac Platform" class="categoryLinkLabel_W154">Module 5: The AI Robot Brain: NVIDIA Isaac Platform</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-06-vla-systems/vla-foundations"><span title="Module 6: Vision–Language–Action (VLA) Systems" class="categoryLinkLabel_W154">Module 6: Vision–Language–Action (VLA) Systems</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-07-humanoid-hri/kinematics-dynamics"><span title="Module 7: Humanoid Systems &amp; Human–Robot Interaction (HRI)" class="categoryLinkLabel_W154">Module 7: Humanoid Systems &amp; Human–Robot Interaction (HRI)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/module-08-capstone-autonomous-humanoid/system-architecture"><span title="Module 8: Capstone - The Autonomous Humanoid System" class="categoryLinkLabel_W154">Module 8: Capstone - The Autonomous Humanoid System</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-08-capstone-autonomous-humanoid/system-architecture"><span title="Chapter 1: System Architecture &amp; Data Flow" class="linkLabel_WmDU">Chapter 1: System Architecture &amp; Data Flow</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/module-08-capstone-autonomous-humanoid/voice-to-plan"><span title="Chapter 2: Voice-to-Plan Pipeline" class="linkLabel_WmDU">Chapter 2: Voice-to-Plan Pipeline</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-08-capstone-autonomous-humanoid/perception-grounding"><span title="Chapter 3: Perception &amp; Grounding" class="linkLabel_WmDU">Chapter 3: Perception &amp; Grounding</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-08-capstone-autonomous-humanoid/action-navigation"><span title="Chapter 4: Action Execution &amp; Navigation" class="linkLabel_WmDU">Chapter 4: Action Execution &amp; Navigation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-08-capstone-autonomous-humanoid/deployment-evaluation"><span title="Chapter 5: Deployment, Evaluation &amp; Failure Recovery" class="linkLabel_WmDU">Chapter 5: Deployment, Evaluation &amp; Failure Recovery</span></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 8: Capstone - The Autonomous Humanoid System</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Chapter 2: Voice-to-Plan Pipeline</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Chapter 2: Voice-to-Plan Pipeline</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction" translate="no">​</a></h2>
<p>This chapter focuses on transforming natural language voice commands into structured task plans that can be executed by the autonomous humanoid system. You&#x27;ll learn how to connect voice processing with LLM reasoning to create robust pipelines that convert human intent into executable actions.</p>
<p>The voice-to-plan pipeline represents a critical integration point between human communication and robotic action. This chapter builds on the voice processing concepts from <a class="" href="/docs/module-06-vla-systems/voice-language">Module 6</a> and connects them with the LLM reasoning concepts from <a class="" href="/docs/module-05-isaac-ai-brain/learning-sim2real">Module 5</a>. This chapter emphasizes the connection between language understanding and physical execution, ensuring that abstract commands are translated into concrete, safe actions. The pipeline must handle ambiguity, validate intentions, and create structured plans that the rest of the system can execute reliably.</p>
<p>By the end of this chapter, you&#x27;ll understand how to create voice-to-plan pipelines that connect human intent to robotic action while maintaining safety and reliability throughout the translation process.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="core-concepts">Core Concepts<a href="#core-concepts" class="hash-link" aria-label="Direct link to Core Concepts" title="Direct link to Core Concepts" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="speech-to-text-processing">Speech-to-Text Processing<a href="#speech-to-text-processing" class="hash-link" aria-label="Direct link to Speech-to-Text Processing" title="Direct link to Speech-to-Text Processing" translate="no">​</a></h3>
<p>The initial conversion of voice commands into textual form that can be processed by LLMs and other components.</p>
<p><strong>Processing Steps:</strong></p>
<ol>
<li class=""><strong>Audio Capture</strong>: Collect voice input with appropriate noise filtering</li>
<li class=""><strong>Transcription</strong>: Convert speech to text using models like Whisper</li>
<li class=""><strong>Quality Assessment</strong>: Evaluate transcription confidence and clarity</li>
<li class=""><strong>Preprocessing</strong>: Clean and format text for LLM processing</li>
</ol>
<p><strong>Quality Considerations:</strong></p>
<ul>
<li class=""><strong>Noise Filtering</strong>: Remove background noise and interference</li>
<li class=""><strong>Speaker Isolation</strong>: Focus on primary speaker in multi-person environments</li>
<li class=""><strong>Confidence Scoring</strong>: Assess reliability of transcription results</li>
<li class=""><strong>Context Preservation</strong>: Maintain temporal and semantic context</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="intent-parsing">Intent Parsing<a href="#intent-parsing" class="hash-link" aria-label="Direct link to Intent Parsing" title="Direct link to Intent Parsing" translate="no">​</a></h3>
<p>The process of extracting actionable intent from transcribed text using LLMs and structured analysis.</p>
<p><strong>Parsing Components:</strong></p>
<ul>
<li class=""><strong>Entity Recognition</strong>: Identify objects, locations, and actions in the command</li>
<li class=""><strong>Relationship Mapping</strong>: Understand spatial and temporal relationships</li>
<li class=""><strong>Task Decomposition</strong>: Break complex commands into executable steps</li>
<li class=""><strong>Constraint Extraction</strong>: Identify safety and execution constraints</li>
</ul>
<p><strong>Parsing Strategies:</strong></p>
<ul>
<li class=""><strong>Schema-Based</strong>: Use predefined templates for common command types</li>
<li class=""><strong>LLM-Based</strong>: Leverage large language models for flexible understanding</li>
<li class=""><strong>Validation Layer</strong>: Cross-check parsed intent with available capabilities</li>
<li class=""><strong>Ambiguity Resolution</strong>: Handle unclear or conflicting information</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="task-schemas">Task Schemas<a href="#task-schemas" class="hash-link" aria-label="Direct link to Task Schemas" title="Direct link to Task Schemas" translate="no">​</a></h3>
<p>Structured representations of tasks that can be validated and executed by the system.</p>
<p><strong>Schema Components:</strong></p>
<ul>
<li class=""><strong>Action Sequence</strong>: Ordered list of actions to execute</li>
<li class=""><strong>Object References</strong>: Specific objects to interact with</li>
<li class=""><strong>Location Constraints</strong>: Where actions should occur</li>
<li class=""><strong>Safety Boundaries</strong>: Constraints to ensure safe execution</li>
</ul>
<p><strong>Schema Validation:</strong></p>
<ul>
<li class=""><strong>Feasibility Check</strong>: Verify tasks are physically possible</li>
<li class=""><strong>Safety Validation</strong>: Ensure no safety boundaries are violated</li>
<li class=""><strong>Resource Availability</strong>: Confirm required resources are available</li>
<li class=""><strong>Dependency Resolution</strong>: Order actions appropriately</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="ambiguity-resolution">Ambiguity Resolution<a href="#ambiguity-resolution" class="hash-link" aria-label="Direct link to Ambiguity Resolution" title="Direct link to Ambiguity Resolution" translate="no">​</a></h3>
<p>Strategies for handling unclear or ambiguous voice commands that require clarification.</p>
<p><strong>Resolution Approaches:</strong></p>
<ul>
<li class=""><strong>Context-Based</strong>: Use environmental context to resolve ambiguity</li>
<li class=""><strong>Perception-Based</strong>: Use vision systems to identify ambiguous objects</li>
<li class=""><strong>Query-Based</strong>: Request clarification from the human user</li>
<li class=""><strong>Default-Based</strong>: Apply safe defaults when ambiguity cannot be resolved</li>
</ul>
<p><strong>Safety Considerations:</strong></p>
<ul>
<li class=""><strong>Conservative Defaults</strong>: Choose safe options when uncertain</li>
<li class=""><strong>User Confirmation</strong>: Request approval for potentially risky interpretations</li>
<li class=""><strong>Fallback Strategies</strong>: Provide alternative execution paths when ambiguous</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="examples">Examples<a href="#examples" class="hash-link" aria-label="Direct link to Examples" title="Direct link to Examples" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-voice-command--json-task-plan">Example: Voice Command → JSON Task Plan<a href="#example-voice-command--json-task-plan" class="hash-link" aria-label="Direct link to Example: Voice Command → JSON Task Plan" title="Direct link to Example: Voice Command → JSON Task Plan" translate="no">​</a></h3>
<p><strong>Voice Command:</strong> &quot;Please go to the kitchen table and bring me the red mug from there to the living room couch.&quot;</p>
<p><strong>Processing Pipeline:</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">1. Speech-to-Text:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Input: Audio &quot;Please go to the kitchen table and bring me the red mug from there to the living room couch.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Output: &quot;Please go to the kitchen table and bring me the red mug from there to the living room couch.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Intent Parsing:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Action: Navigate → Grasp → Navigate → Place</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Source: kitchen table, red mug</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Destination: living room couch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Object: red mug</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Task Schema Generation:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     &quot;id&quot;: &quot;task_001&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     &quot;actions&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;type&quot;: &quot;navigate&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;target&quot;: &quot;kitchen table&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;constraints&quot;: {&quot;max_distance&quot;: 5.0, &quot;safety_radius&quot;: 1.0}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;type&quot;: &quot;locate&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;object&quot;: &quot;red mug&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;reference&quot;: &quot;kitchen table&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;constraints&quot;: {&quot;search_timeout&quot;: 30, &quot;confidence_threshold&quot;: 0.8}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;type&quot;: &quot;grasp&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;object&quot;: &quot;red mug&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;constraints&quot;: {&quot;grasp_type&quot;: &quot;precision&quot;, &quot;force_limit&quot;: 10.0}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;type&quot;: &quot;navigate&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;target&quot;: &quot;living room couch&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;constraints&quot;: {&quot;max_distance&quot;: 10.0, &quot;safety_radius&quot;: 1.0}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;type&quot;: &quot;place&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;object&quot;: &quot;red mug&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;target&quot;: &quot;living room couch&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">         &quot;constraints&quot;: {&quot;placement_type&quot;: &quot;safe&quot;, &quot;height&quot;: 0.5}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">       }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     &quot;safety_boundaries&quot;: [&quot;human_safety_zone&quot;, &quot;navigation_obstacles&quot;],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">     &quot;validation_requirements&quot;: [&quot;object_existence&quot;, &quot;path_clearance&quot;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   }</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-validation-rules">Example: Validation Rules<a href="#example-validation-rules" class="hash-link" aria-label="Direct link to Example: Validation Rules" title="Direct link to Example: Validation Rules" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Validation Rule Set for Voice-to-Plan Pipeline:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1. Object Existence Validation:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Before: &quot;red mug&quot; must exist in environment</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - How: Use perception system to locate object</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - If Missing: Report error, suggest alternatives</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2. Path Feasibility Validation:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Before: Navigation paths must be clear</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - How: Use navigation system to plan path</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - If Blocked: Find alternative route or abort</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">3. Safety Boundary Validation:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Before: No safety boundaries violated</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - How: Check human safety zones, restricted areas</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - If Violated: Abort and report safety concern</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4. Capability Validation:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - Before: Robot can perform requested actions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - How: Check manipulation and navigation capabilities</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   - If Unsupported: Report capability limitation</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="example-voice-processing-pipeline">Example: Voice Processing Pipeline<a href="#example-voice-processing-pipeline" class="hash-link" aria-label="Direct link to Example: Voice Processing Pipeline" title="Direct link to Example: Voice Processing Pipeline" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[Voice Input] → [Audio Preprocessing] → [Speech-to-Text] → [Text Validation]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ↓               ↓                      ↓                ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[Noise Filter]  [Volume Normalization]  [Confidence Score] [Format Cleaning]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[Intent Parsing] → [Entity Recognition] → [Task Decomposition] → [Schema Validation]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ↓                 ↓                      ↓                    ↓</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[LLM Processing]  [Object/Location Tags]  [Action Sequence]   [Safety Check]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[Task Plan Output] → [Execution Readiness]</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary--key-takeaways">Summary &amp; Key Takeaways<a href="#summary--key-takeaways" class="hash-link" aria-label="Direct link to Summary &amp; Key Takeaways" title="Direct link to Summary &amp; Key Takeaways" translate="no">​</a></h2>
<p>In this chapter, you learned about the voice-to-plan pipeline:</p>
<ul>
<li class=""><strong>Speech-to-text processing</strong> converts voice commands to textual form for further processing</li>
<li class=""><strong>Intent parsing</strong> extracts actionable meaning from natural language using LLMs</li>
<li class=""><strong>Task schemas</strong> provide structured representations that can be validated and executed</li>
<li class=""><strong>Ambiguity resolution</strong> handles unclear commands with safety-first approaches</li>
</ul>
<p>The voice-to-plan pipeline serves as the bridge between human communication and robotic action, requiring careful attention to safety, validation, and reliability. This chapter connects the voice processing concepts from earlier modules with the action execution capabilities that will be covered in later chapters.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/muhammadNadeem92/physical-ai-humanoid-robotics-textbook/tree/main/docs/module-08-capstone-autonomous-humanoid/voice-to-plan.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/module-08-capstone-autonomous-humanoid/system-architecture"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Chapter 1: System Architecture &amp; Data Flow</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/module-08-capstone-autonomous-humanoid/perception-grounding"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Chapter 3: Perception &amp; Grounding</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#core-concepts" class="table-of-contents__link toc-highlight">Core Concepts</a><ul><li><a href="#speech-to-text-processing" class="table-of-contents__link toc-highlight">Speech-to-Text Processing</a></li><li><a href="#intent-parsing" class="table-of-contents__link toc-highlight">Intent Parsing</a></li><li><a href="#task-schemas" class="table-of-contents__link toc-highlight">Task Schemas</a></li><li><a href="#ambiguity-resolution" class="table-of-contents__link toc-highlight">Ambiguity Resolution</a></li></ul></li><li><a href="#examples" class="table-of-contents__link toc-highlight">Examples</a><ul><li><a href="#example-voice-command--json-task-plan" class="table-of-contents__link toc-highlight">Example: Voice Command → JSON Task Plan</a></li><li><a href="#example-validation-rules" class="table-of-contents__link toc-highlight">Example: Validation Rules</a></li><li><a href="#example-voice-processing-pipeline" class="table-of-contents__link toc-highlight">Example: Voice Processing Pipeline</a></li></ul></li><li><a href="#summary--key-takeaways" class="table-of-contents__link toc-highlight">Summary &amp; Key Takeaways</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Textbook</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/muhammadNadeem92/physical-ai-humanoid-robotics-textbook" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics Textbook. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>